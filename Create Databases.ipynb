{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import COLLECTIONS as cln\n",
    "from IPython.display import clear_output\n",
    "import html5lib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "cnx = create_engine('postgresql://%s:%s@localhost:%s/%s' % (cln.username, \n",
    "                                                            cln.password, \n",
    "                                                            cln.port,\n",
    "                                                            cln.db_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>FAA</th>\n",
       "      <th>IATA</th>\n",
       "      <th>ICAO</th>\n",
       "      <th>Airport</th>\n",
       "      <th>Role</th>\n",
       "      <th>Enplanements</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Birmingham</td>\n",
       "      <td>BHM</td>\n",
       "      <td>BHM</td>\n",
       "      <td>KBHM</td>\n",
       "      <td>Birmingham–Shuttlesworth International Airport</td>\n",
       "      <td>P-S</td>\n",
       "      <td>1325897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dothan</td>\n",
       "      <td>DHN</td>\n",
       "      <td>DHN</td>\n",
       "      <td>KDHN</td>\n",
       "      <td>Dothan Regional Airport</td>\n",
       "      <td>P-N</td>\n",
       "      <td>46792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Huntsville</td>\n",
       "      <td>HSV</td>\n",
       "      <td>HSV</td>\n",
       "      <td>KHSV</td>\n",
       "      <td>Huntsville International Airport (Carl T. Jone...</td>\n",
       "      <td>P-S</td>\n",
       "      <td>519785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mobile</td>\n",
       "      <td>MOB</td>\n",
       "      <td>MOB</td>\n",
       "      <td>KMOB</td>\n",
       "      <td>Mobile Regional Airport</td>\n",
       "      <td>P-N</td>\n",
       "      <td>278053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Montgomery</td>\n",
       "      <td>MGM</td>\n",
       "      <td>MGM</td>\n",
       "      <td>KMGM</td>\n",
       "      <td>Montgomery Regional Airport (Dannelly Field)</td>\n",
       "      <td>P-N</td>\n",
       "      <td>175619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         City  FAA IATA  ICAO  \\\n",
       "1  Birmingham  BHM  BHM  KBHM   \n",
       "2      Dothan  DHN  DHN  KDHN   \n",
       "3  Huntsville  HSV  HSV  KHSV   \n",
       "4      Mobile  MOB  MOB  KMOB   \n",
       "5  Montgomery  MGM  MGM  KMGM   \n",
       "\n",
       "                                             Airport Role  Enplanements  \n",
       "1     Birmingham–Shuttlesworth International Airport  P-S       1325897  \n",
       "2                            Dothan Regional Airport  P-N         46792  \n",
       "3  Huntsville International Airport (Carl T. Jone...  P-S        519785  \n",
       "4                            Mobile Regional Airport  P-N        278053  \n",
       "5       Montgomery Regional Airport (Dannelly Field)  P-N        175619  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrape Primary Airport Names\n",
    "df_primary_airports = pd.read_html('https://en.wikipedia.org/wiki/List_of_airports_in_the_United_States', \n",
    "                                 attrs={\"class\":\"wikitable\"}, header=0)[0]\n",
    "df_primary_airports.dropna(inplace=True)\n",
    "df_primary_airports['Enplanements'] = df_primary_airports['Enplanements'].apply(lambda x: int(x.replace(',','').split(' ')[0]))\n",
    "df_primary_airports.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_primary_airports = df_primary_airports[df_primary_airports['Enplanements'] > 500000]\n",
    "df_primary_airports.to_sql('primary_airports', cnx, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_table = {\n",
    "    'airlines': False,\n",
    "    'airports': False,\n",
    "    'ontimeperformance': True,\n",
    "    'weather': False,\n",
    "    'weatherairportlinks': False,\n",
    "    'weatherstations': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update Airlines Table\n",
    "table_name = 'airlines'\n",
    "\n",
    "if make_table[table_name]:\n",
    "    # Load Data\n",
    "    df = pd.read_csv('airlines.dat', header=None)\n",
    "    df.columns = ['AirlineID', 'Name', '', 'IATA', '', 'Callsign', 'Country', '']\n",
    "\n",
    "    # Filter Data\n",
    "    mask = ((df['AirlineID'] > 0) &\n",
    "            (~df['IATA'].apply(str).isin(['-', 'nan'])) &\n",
    "            (~df['Callsign'].apply(str).isin(['-', 'nan'])) &\n",
    "            (df['Country'] == 'United States'))\n",
    "    df.drop('', axis=1, inplace=True)\n",
    "    df = df[mask]\n",
    "    df.dropna()\n",
    "    df['AirlineID'] = df['AirlineID'].apply(int)\n",
    "\n",
    "    # Insert into table\n",
    "    df.to_sql(table_name, cnx, if_exists='replace', index=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AirlineID</th>\n",
       "      <th>Name</th>\n",
       "      <th>IATA</th>\n",
       "      <th>Callsign</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>40-Mile Air</td>\n",
       "      <td>Q5</td>\n",
       "      <td>MILE-AIR</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>Aloha Airlines</td>\n",
       "      <td>AQ</td>\n",
       "      <td>ALOHA</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>American Airlines</td>\n",
       "      <td>AA</td>\n",
       "      <td>AMERICAN</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>Allegiant Air</td>\n",
       "      <td>G4</td>\n",
       "      <td>ALLEGIANT</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>Airborne Express</td>\n",
       "      <td>GB</td>\n",
       "      <td>ABEX</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AirlineID               Name IATA   Callsign        Country\n",
       "0         10        40-Mile Air   Q5   MILE-AIR  United States\n",
       "1         22     Aloha Airlines   AQ      ALOHA  United States\n",
       "2         24  American Airlines   AA   AMERICAN  United States\n",
       "3         35      Allegiant Air   G4  ALLEGIANT  United States\n",
       "4         49   Airborne Express   GB       ABEX  United States"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Airlines Table\n",
    "df_read = pd.read_sql_query(\"\"\"SELECT * FROM Airlines\"\"\", cnx)\n",
    "df_read.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Update Airlines Table\n",
    "table_name = 'airports'\n",
    "\n",
    "if make_table[table_name]:\n",
    "\n",
    "    # Load Data\n",
    "    df = pd.read_csv('airports.dat', header=None)\n",
    "    df.columns = ['AirportID', 'Name', 'City', 'Country', 'IATA', '',\n",
    "                  'Latitude', 'Longitude', 'Altitude', 'Timezone',\n",
    "                  'DST', 'Tz_Database_Timezone', 'Type', 'Source']\n",
    "    df.drop('', axis=1, inplace=True)\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "    df = df[df['Timezone'] != '\\\\N']\n",
    "\n",
    "    df['AirportID'] = df['AirportID'].apply(int)\n",
    "    df['Latitude'] = df['Latitude'].apply(float)\n",
    "    df['Longitude'] = df['Longitude'].apply(float)\n",
    "    df['Altitude'] = df['Altitude'].apply(int)\n",
    "    df['Timezone'] = df['Timezone'].apply(float)\n",
    "\n",
    "    df.to_sql(name=table_name, con=cnx, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AirportID</th>\n",
       "      <th>Name</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>IATA</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Altitude</th>\n",
       "      <th>Timezone</th>\n",
       "      <th>DST</th>\n",
       "      <th>Tz_Database_Timezone</th>\n",
       "      <th>Type</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Goroka Airport</td>\n",
       "      <td>Goroka</td>\n",
       "      <td>Papua New Guinea</td>\n",
       "      <td>GKA</td>\n",
       "      <td>-6.081690</td>\n",
       "      <td>145.391998</td>\n",
       "      <td>5282</td>\n",
       "      <td>10.0</td>\n",
       "      <td>U</td>\n",
       "      <td>Pacific/Port_Moresby</td>\n",
       "      <td>airport</td>\n",
       "      <td>OurAirports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Madang Airport</td>\n",
       "      <td>Madang</td>\n",
       "      <td>Papua New Guinea</td>\n",
       "      <td>MAG</td>\n",
       "      <td>-5.207080</td>\n",
       "      <td>145.789001</td>\n",
       "      <td>20</td>\n",
       "      <td>10.0</td>\n",
       "      <td>U</td>\n",
       "      <td>Pacific/Port_Moresby</td>\n",
       "      <td>airport</td>\n",
       "      <td>OurAirports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Mount Hagen Kagamuga Airport</td>\n",
       "      <td>Mount Hagen</td>\n",
       "      <td>Papua New Guinea</td>\n",
       "      <td>HGU</td>\n",
       "      <td>-5.826790</td>\n",
       "      <td>144.296005</td>\n",
       "      <td>5388</td>\n",
       "      <td>10.0</td>\n",
       "      <td>U</td>\n",
       "      <td>Pacific/Port_Moresby</td>\n",
       "      <td>airport</td>\n",
       "      <td>OurAirports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Nadzab Airport</td>\n",
       "      <td>Nadzab</td>\n",
       "      <td>Papua New Guinea</td>\n",
       "      <td>LAE</td>\n",
       "      <td>-6.569803</td>\n",
       "      <td>146.725977</td>\n",
       "      <td>239</td>\n",
       "      <td>10.0</td>\n",
       "      <td>U</td>\n",
       "      <td>Pacific/Port_Moresby</td>\n",
       "      <td>airport</td>\n",
       "      <td>OurAirports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Port Moresby Jacksons International Airport</td>\n",
       "      <td>Port Moresby</td>\n",
       "      <td>Papua New Guinea</td>\n",
       "      <td>POM</td>\n",
       "      <td>-9.443380</td>\n",
       "      <td>147.220001</td>\n",
       "      <td>146</td>\n",
       "      <td>10.0</td>\n",
       "      <td>U</td>\n",
       "      <td>Pacific/Port_Moresby</td>\n",
       "      <td>airport</td>\n",
       "      <td>OurAirports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AirportID                                         Name          City  \\\n",
       "0          1                               Goroka Airport        Goroka   \n",
       "1          2                               Madang Airport        Madang   \n",
       "2          3                 Mount Hagen Kagamuga Airport   Mount Hagen   \n",
       "3          4                               Nadzab Airport        Nadzab   \n",
       "4          5  Port Moresby Jacksons International Airport  Port Moresby   \n",
       "\n",
       "            Country IATA  Latitude   Longitude  Altitude  Timezone DST  \\\n",
       "0  Papua New Guinea  GKA -6.081690  145.391998      5282      10.0   U   \n",
       "1  Papua New Guinea  MAG -5.207080  145.789001        20      10.0   U   \n",
       "2  Papua New Guinea  HGU -5.826790  144.296005      5388      10.0   U   \n",
       "3  Papua New Guinea  LAE -6.569803  146.725977       239      10.0   U   \n",
       "4  Papua New Guinea  POM -9.443380  147.220001       146      10.0   U   \n",
       "\n",
       "   Tz_Database_Timezone     Type       Source  \n",
       "0  Pacific/Port_Moresby  airport  OurAirports  \n",
       "1  Pacific/Port_Moresby  airport  OurAirports  \n",
       "2  Pacific/Port_Moresby  airport  OurAirports  \n",
       "3  Pacific/Port_Moresby  airport  OurAirports  \n",
       "4  Pacific/Port_Moresby  airport  OurAirports  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Airlines Table\n",
    "df_read = pd.read_sql_query(\"\"\"SELECT * FROM airports\"\"\", cnx)\n",
    "df_read.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import WeatherStations\n",
    "table_name = 'weatherstations'\n",
    "\n",
    "if make_table[table_name]:\n",
    "    with open('ghcnd-stations.txt', 'r') as file:\n",
    "        x = file.read()\n",
    "    x = x.split('\\n')\n",
    "    x = [i.strip() for i in x]\n",
    "    x_left = [i.split()[:4] for i in x]\n",
    "    x_right = [i[41:].split('  ')[0] for i in x]\n",
    "    x_right = [i.strip() for i in x_right]\n",
    "    x = [i + [j] for i,j in zip(x_left, x_right)]\n",
    "\n",
    "    df = pd.DataFrame(x, columns=['StationID', 'Latitude', 'Longitude', 'Altitude_ft', 'Name'])\n",
    "    df = df[df['StationID'] != '']\n",
    "    df['Altitude_ft'] = df['Altitude_ft'].apply(float)*3.28084\n",
    "    df['Name'] = df['Name'].apply(lambda item: ' '.join([i.capitalize() for i in item.split()]))\n",
    "    df['Latitude'] = df['Latitude'].apply(float)\n",
    "    df['Longitude'] = df['Longitude'].apply(float)\n",
    "\n",
    "    df.to_sql(name=table_name, con=cnx, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StationID</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Altitude_ft</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACW00011604</td>\n",
       "      <td>17.1167</td>\n",
       "      <td>-61.7833</td>\n",
       "      <td>33.136484</td>\n",
       "      <td>St Johns Coolidge Fld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACW00011647</td>\n",
       "      <td>17.1333</td>\n",
       "      <td>-61.7833</td>\n",
       "      <td>62.992128</td>\n",
       "      <td>St Johns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>25.3330</td>\n",
       "      <td>55.5170</td>\n",
       "      <td>111.548560</td>\n",
       "      <td>Sharjah Inter. Airp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AEM00041194</td>\n",
       "      <td>25.2550</td>\n",
       "      <td>55.3640</td>\n",
       "      <td>34.120736</td>\n",
       "      <td>Dubai Intl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AEM00041217</td>\n",
       "      <td>24.4330</td>\n",
       "      <td>54.6510</td>\n",
       "      <td>87.926512</td>\n",
       "      <td>Abu Dhabi Intl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     StationID  Latitude  Longitude  Altitude_ft                   Name\n",
       "0  ACW00011604   17.1167   -61.7833    33.136484  St Johns Coolidge Fld\n",
       "1  ACW00011647   17.1333   -61.7833    62.992128               St Johns\n",
       "2  AE000041196   25.3330    55.5170   111.548560    Sharjah Inter. Airp\n",
       "3  AEM00041194   25.2550    55.3640    34.120736             Dubai Intl\n",
       "4  AEM00041217   24.4330    54.6510    87.926512         Abu Dhabi Intl"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Airlines Table\n",
    "df_read = pd.read_sql_query(\"\"\"SELECT * FROM weatherstations\"\"\", cnx)\n",
    "df_read.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Weather Station Links\n",
    "table_name = 'weatherairportlinks'\n",
    "\n",
    "if make_table[table_name]:\n",
    "    df_airports = pd.read_sql_query(\"\"\"SELECT \"IATA\", \"Latitude\", \"Longitude\" FROM airports\"\"\", cnx)\n",
    "    df_airports.set_index('IATA', inplace=True)\n",
    "    df_stations = pd.read_sql_query(\"\"\"SELECT \"StationID\", \"Latitude\", \"Longitude\", \"Name\" FROM weatherstations\"\"\", cnx)\n",
    "    df_stations.set_index('StationID', inplace=True)\n",
    "\n",
    "    df_link = {}\n",
    "    i = 1\n",
    "    for use_airport in df_airports.index.values:\n",
    "        clear_output(wait=True)\n",
    "        print('%d/%d' % (i, len(df_airports.index.values)))\n",
    "    #     print(df_stations['Latitude'])\n",
    "        if len(use_airport) != 3:\n",
    "            i += 1\n",
    "            continue\n",
    "    #     print(use_airport)\n",
    "    #     print(df_airports.loc[use_airport]['Latitude'])\n",
    "        df_stations['lat_dif'] = abs(df_stations['Latitude'] - df_airports.loc[use_airport]['Latitude'])\n",
    "        df_stations['lon_dif'] = abs(df_stations['Longitude'] - df_airports.loc[use_airport]['Longitude'])\n",
    "        df_stations['sum_dif'] = df_stations['lon_dif'] + df_stations['lat_dif']\n",
    "    #     print(df_stations.sort_values('sum_dif')['sum_dif'].iloc[0])\n",
    "        df_link[use_airport] = df_stations.sort_values('sum_dif').index[0]\n",
    "        i += 1\n",
    "\n",
    "    df = pd.DataFrame(pd.Series(df_link)).reset_index()\n",
    "    df.columns = ['IATA', 'StationID']\n",
    "\n",
    "    df.to_sql(name=table_name, con=cnx, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import Weather Data\n",
    "import shutil\n",
    "import os\n",
    "import zipfile\n",
    "import gzip\n",
    "\n",
    "table_name = 'weather'\n",
    "\n",
    "if make_table[table_name]:\n",
    "    path = 'Data/Weather/'\n",
    "    idx = 1\n",
    "    \n",
    "    print(\"Make initial queries...\")\n",
    "    df_links = pd.read_sql_query(\"\"\"SELECT * FROM weatherairportlinks\"\"\", cnx)\n",
    "    df_completed_years = pd.read_sql_query(\"\"\"select distinct extract(year from \"Date\") from weather;\"\"\", cnx)\n",
    "\n",
    "    for fn in os.listdir(path):\n",
    "        clear_output(wait=True)\n",
    "        print(\"(%d/%d) %s\" % (idx, len(os.listdir(path)), fn))\n",
    "        print('Data')\n",
    "        if not fn.endswith('.csv.gz'):\n",
    "            continue\n",
    "        if fn.split('.')[0] in [str(int(i[0])) for i in df_completed_years.values]:\n",
    "            idx += 1\n",
    "            continue\n",
    "\n",
    "        print('Unzipping...')\n",
    "        try:\n",
    "            os.mkdir(path + 'output/', )\n",
    "        except OSError:\n",
    "            pass\n",
    "        with gzip.open(path + fn, 'rb') as f_in, open(path + 'output/' + fn.replace('.gz',''), 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "        print('Reading CSV')\n",
    "        df = pd.read_csv(path + 'output/' + fn.replace('.gz', ''), header=None)\n",
    "        shutil.rmtree(path + 'output', )\n",
    "\n",
    "        print('Processing Data')\n",
    "        df.drop([4,5,6,7], axis=1, inplace=True)\n",
    "        df.columns = ['StationID', 'Date', 'Obsv_Type', 'Obsv_Value']\n",
    "        df['Date'] = pd.to_datetime(df['Date'], format='%Y%m%d')\n",
    "        df = df.merge(df_links, on='StationID')[['StationID', 'Date', 'Obsv_Type', 'Obsv_Value']]\n",
    "\n",
    "        print('Adding to Database')\n",
    "        sections = range(0, len(df), 1000000)\n",
    "        for sect in range(len(sections)):\n",
    "            if idx == 1 and sect == 0:\n",
    "                if_exists = 'replace'\n",
    "            else:\n",
    "                if_exists = 'append'\n",
    "            if sect == 0:\n",
    "                subset_min = sections[sect]\n",
    "                subset_max = sections[sect+1]\n",
    "            elif sect == len(sections)-1:\n",
    "                subset_min = sections[sect]\n",
    "                subset_max = ''\n",
    "            else:\n",
    "                subset_min = sections[sect]\n",
    "                subset_max = sections[sect+1]\n",
    "            print('Part %d/%d (%s:%s)' % (sect+1, \n",
    "                                          len(sections),\n",
    "                                          str(subset_min),\n",
    "                                          str(subset_max)))\n",
    "            if subset_max == '':\n",
    "                df.iloc[subset_min:].to_sql(name=table_name, \n",
    "                                            con=cnx, \n",
    "                                            if_exists=if_exists, \n",
    "                                            index=False)\n",
    "            else:\n",
    "                df.iloc[subset_min:subset_max].to_sql(name=table_name, \n",
    "                                                      con=cnx, \n",
    "                                                      if_exists=if_exists, \n",
    "                                                      index=False)\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping File On_Time_On_Time_Performance_2010_1.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2010_10.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2010_11.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2010_12.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2010_2.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2010_3.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2010_4.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2010_5.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2010_6.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2010_7.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2010_8.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2010_9.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2011_1.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2011_10.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2011_11.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2011_12.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2011_2.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2011_3.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2011_4.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2011_5.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2011_6.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2011_7.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2011_8.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2011_9.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2012_1.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2012_10.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2012_11.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2012_12.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2012_2.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2012_3.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2012_4.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2012_5.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2012_6.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2012_7.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2012_8.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2012_9.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2013_1.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2013_10.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2013_11.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2013_12.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2013_2.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2013_3.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2013_4.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2013_5.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2013_6.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2013_7.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2013_8.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2013_9.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2014_1.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2014_10.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2014_11.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2014_12.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2014_2.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2014_3.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2014_4.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2014_5.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2014_6.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2014_7.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2014_8.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2014_9.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2015_1.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2015_10.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2015_11.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2015_12.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2015_2.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2015_3.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2015_4.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2015_5.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2015_6.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2015_7.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2015_8.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2015_9.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2016_1.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2016_10.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2016_11.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2016_12.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2016_2.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2016_3.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2016_4.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2016_5.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2016_6.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2016_7.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2016_8.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2016_9.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2017_1.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2017_10.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2017_11.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2017_2.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2017_3.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2017_4.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2017_5.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2017_6.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2017_7.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2017_8.zip (already in database)\n",
      "Skipping File On_Time_On_Time_Performance_2017_9.zip (already in database)\n"
     ]
    }
   ],
   "source": [
    "# Import Ontime Flight Performance Data\n",
    "import shutil\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "table_name = 'ontimeperformance'\n",
    "\n",
    "if make_table[table_name]:\n",
    "    path = 'Data/'\n",
    "\n",
    "    def create_ids(data):\n",
    "        ids = (data['FlightDate'].apply(lambda x: str(x).replace('-','_')) + \n",
    "               data['AirlineID'].apply(str) + \n",
    "               data['ArrTime'].apply(lambda x: str(x).split('.')[0]) + \n",
    "               data['DestAirportID'].apply(str) + \n",
    "               data['OriginAirportID'].apply(str) + \n",
    "               data['TailNum'].apply(str))\n",
    "        return ids\n",
    "\n",
    "    def int_to_time(x):\n",
    "        import datetime as dt\n",
    "        try:\n",
    "            hour = int(x)//100\n",
    "            if hour > 23:\n",
    "                hour = hour - 24\n",
    "            minute = int(x) - int(x)//100*100\n",
    "            return dt.time(hour, minute)\n",
    "        except:\n",
    "            return dt.time(0, 0)\n",
    "\n",
    "    i = 1\n",
    "    current_files = pd.read_sql_query(\"\"\"select distinct \"File_Name\" from ontimeperformance;\"\"\", cnx).values\n",
    "    for fn in sorted(os.listdir(path)):\n",
    "        if fn.startswith('On_Time_On_Time_Performance'):\n",
    "            if fn in [i[0] for i in current_files]:\n",
    "                print(\"Skipping File %s (already in database)\" % fn)\n",
    "                i += 1\n",
    "                continue\n",
    "            print('(%d/%d) %s' % (i, len(os.listdir(path)), fn))\n",
    "            zip = zipfile.ZipFile(path+fn)  \n",
    "            zip.extractall(path + 'output')\n",
    "            df = pd.read_csv(path + 'output/' + fn.replace('.zip', '.csv'))\n",
    "            shutil.rmtree(path + 'output', )\n",
    "            base_row_count = len(df)\n",
    "            df.dropna(subset=['ArrDelay'], inplace=True)\n",
    "            df['PerformanceID'] = create_ids(df)\n",
    "            df['File_Name'] = [fn]*len(df)\n",
    "            df['FlightDate'] = pd.to_datetime(df['FlightDate'])\n",
    "            print(\"Dropped %d Rows (%0.4f%%).\" % (base_row_count - len(df), (base_row_count-len(df))/base_row_count*100))\n",
    "            print('-----')\n",
    "            print(\"Processing Data\")\n",
    "            keep_columns = ['PerformanceID', 'File_Name', 'FlightDate', 'Carrier', 'TailNum', 'FlightNum', \n",
    "                            'Origin', 'OriginCityName', 'OriginStateName',\n",
    "                            'Dest', 'DestCityName', 'DestStateName',\n",
    "                            'CRSDepTime', 'DepTime', 'DepTimeBlk', 'DepDelay', 'DepDelayMinutes', 'DepDel15',\n",
    "                            'CRSArrTime', 'ArrTime', 'ArrTimeBlk', 'ArrDelay', 'ArrDelayMinutes', 'ArrDel15',\n",
    "                            'TaxiOut', 'WheelsOff', 'WheelsOn', 'TaxiIn',\n",
    "                            'Cancelled', 'Diverted', 'CRSElapsedTime', 'ActualElapsedTime', \n",
    "                            'AirTime', 'Flights', 'Distance', 'DistanceGroup', 'CarrierDelay', \n",
    "                            'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay', \n",
    "                            'FirstDepTime', 'TotalAddGTime', 'LongestAddGTime']\n",
    "            # Cleaning\n",
    "            df['OriginCityName'] = df['OriginCityName'].apply(lambda x: x.split(',')[0])\n",
    "            df['DestCityName'] = df['DestCityName'].apply(lambda x: x.split(',')[0])\n",
    "            df['CRSDepTime'] = df['CRSDepTime'].apply(int_to_time)\n",
    "            df['DepTime'] = df['DepTime'].apply(int_to_time)\n",
    "            df['DepDelay'] = df['DepDelay'].apply(float)\n",
    "            df['DepDelayMinutes'] = df['DepDelayMinutes'].apply(float)\n",
    "            df['DepDel15'] = df['DepDel15'].apply(float)\n",
    "            df['CRSArrTime'] = df['CRSArrTime'].apply(int_to_time)\n",
    "            df['ArrTime'] = df['ArrTime'].apply(int_to_time)\n",
    "            df['ArrDelay'] = df['ArrDelay'].apply(float)\n",
    "            df['ArrDelayMinutes'] = df['ArrDelayMinutes'].apply(float)\n",
    "            df['ArrDel15'] = df['ArrDel15'].apply(float)\n",
    "            df['TaxiOut'] = df['TaxiOut'].apply(float)\n",
    "            df['TaxiIn'] = df['TaxiIn'].apply(float)\n",
    "            df['WheelsOff'] = df['WheelsOff'].apply(int_to_time)\n",
    "            df['WheelsOn'] = df['WheelsOn'].apply(int_to_time)\n",
    "            df['Cancelled'] = df['Cancelled'].apply(bool)\n",
    "            df['Diverted'] = df['Diverted'].apply(bool)\n",
    "            df['CRSElapsedTime'] = df['CRSElapsedTime'].apply(float)\n",
    "            df['ActualElapsedTime'] = df['ActualElapsedTime'].apply(float)\n",
    "            df['AirTime'] = df['AirTime'].apply(float)\n",
    "            df['Flights'] = df['Flights'].apply(float)\n",
    "            df['Distance'] = df['Distance'].apply(float)\n",
    "            df['DistanceGroup'] = df['DistanceGroup'].apply(float)\n",
    "            print(\"Writing to Database\")\n",
    "            if i == 1:\n",
    "                if_exists = 'replace'\n",
    "            else:\n",
    "                if_exists = 'append'\n",
    "            df[keep_columns].to_sql(name=table_name, \n",
    "                                    con=cnx, \n",
    "                                    if_exists=if_exists,\n",
    "                                    index=False)\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
